# ƒê·ªÅ Xu·∫•t C·∫£i Thi·ªán Hi·ªáu NƒÉng

## üéØ M·ª•c Ti√™u

C·∫£i thi·ªán 2 ƒëi·ªÉm y·∫øu ƒë√£ ƒë∆∞·ª£c x√°c ƒë·ªãnh trong Security Audit:
1. `split_sql_queries()` - Gi·∫£m RAM usage
2. `run_search_replace()` - Tr√°nh timeout v·ªõi database l·ªõn

---

## üîß C·∫£i Thi·ªán 1: Streaming SQL Parser

### V·∫•n ƒê·ªÅ Hi·ªán T·∫°i

```php
// ‚ùå ƒê·ªçc to√†n b·ªô file v√†o RAM
$sql_content = file_get_contents( $sql_file );
$queries = $this->split_sql_queries( $sql_content ); // Loop t·ª´ng k√Ω t·ª±
```

**RAM Usage**: File 100MB ‚Üí ~300-400MB RAM

### Gi·∫£i Ph√°p: Streaming Parser

```php
/**
 * Split SQL file into queries using streaming (memory efficient)
 *
 * @param string $sql_file Path to SQL file
 * @return array Array of SQL queries
 */
private function split_sql_queries_streaming( $sql_file ) {
    $queries = array();
    $current_query = '';
    $in_string = false;
    $string_char = '';
    
    // Open file handle
    $handle = fopen( $sql_file, 'r' );
    if ( false === $handle ) {
        return array();
    }
    
    // Read file in chunks (1MB at a time)
    $chunk_size = 1024 * 1024; // 1MB
    $buffer = '';
    
    while ( ! feof( $handle ) ) {
        $chunk = fread( $handle, $chunk_size );
        if ( false === $chunk ) {
            break;
        }
        
        $buffer .= $chunk;
        
        // Process buffer character by character
        $buffer_length = strlen( $buffer );
        for ( $i = 0; $i < $buffer_length; $i++ ) {
            $char = $buffer[ $i ];
            
            // Handle string detection
            if ( ! $in_string && ( "'" === $char || '"' === $char || '`' === $char ) ) {
                $in_string = true;
                $string_char = $char;
            } elseif ( $in_string && $char === $string_char ) {
                // Check for escaped quote
                if ( $i > 0 && $buffer[ $i - 1 ] === '\\' ) {
                    // Escaped quote, continue
                } else {
                    $in_string = false;
                    $string_char = '';
                }
            }
            
            $current_query .= $char;
            
            // End of query
            if ( ! $in_string && ';' === $char ) {
                $query = trim( $current_query );
                if ( ! empty( $query ) && '--' !== substr( $query, 0, 2 ) ) {
                    $queries[] = $query;
                }
                $current_query = '';
            }
        }
        
        // Keep remaining part of buffer (in case query spans chunks)
        if ( ! empty( $current_query ) ) {
            $buffer = substr( $buffer, -strlen( $current_query ) );
        } else {
            $buffer = '';
        }
        
        // Free memory periodically
        if ( count( $queries ) % 1000 === 0 ) {
            gc_collect_cycles();
        }
    }
    
    // Add last query if exists
    if ( ! empty( trim( $current_query ) ) ) {
        $queries[] = trim( $current_query );
    }
    
    fclose( $handle );
    
    return array_filter( $queries );
}
```

**RAM Usage**: File 100MB ‚Üí ~10-20MB RAM (ch·ªâ buffer 1MB)

### C√°ch √Åp D·ª•ng

Thay th·∫ø trong `restore_database()`:
```php
// C≈©:
$sql_content = file_get_contents( $sql_file );
$queries = $this->split_sql_queries( $sql_content );

// M·ªõi:
$queries = $this->split_sql_queries_streaming( $sql_file );
```

---

## üîß C·∫£i Thi·ªán 2: Batch Processing cho Search & Replace

### V·∫•n ƒê·ªÅ Hi·ªán T·∫°i

```php
// ‚ùå X·ª≠ l√Ω to√†n b·ªô database trong 1 request
public function run_search_replace( $old_url, $new_url ) {
    @set_time_limit( 600 ); // 10 ph√∫t - nh∆∞ng server c√≥ th·ªÉ kill sau 60s
    // Loop qua t·∫•t c·∫£ tables v√† rows...
}
```

**V·∫•n ƒë·ªÅ**: Database l·ªõn ‚Üí timeout ‚Üí process b·ªã kill gi·ªØa ch·ª´ng

### Gi·∫£i Ph√°p: Batch Processing v·ªõi Resume

#### B∆∞·ªõc 1: Th√™m Progress Tracking

```php
/**
 * Run search and replace with batch processing
 *
 * @param string $old_url Old URL to replace
 * @param string $new_url New URL to replace with
 * @param string $table_name Optional: specific table to process
 * @param int    $offset Optional: offset for chunk processing
 * @return array Status array with 'completed', 'next_table', 'next_offset'
 */
public function run_search_replace_batch( $old_url, $new_url, $table_name = null, $offset = 0 ) {
    global $wpdb;
    
    if ( empty( $old_url ) || empty( $new_url ) ) {
        return array( 'error' => 'URLs required' );
    }
    
    // Normalize URLs
    $old_url = untrailingslashit( $old_url );
    $new_url = untrailingslashit( $new_url );
    
    if ( $old_url === $new_url ) {
        return array( 'completed' => true );
    }
    
    // Get all tables
    $tables = $wpdb->get_results( 'SHOW TABLES', ARRAY_N );
    
    if ( empty( $tables ) ) {
        return array( 'error' => 'No tables found' );
    }
    
    // Find starting point
    $start_index = 0;
    if ( $table_name ) {
        foreach ( $tables as $index => $table ) {
            if ( $table[0] === $table_name ) {
                $start_index = $index;
                break;
            }
        }
    }
    
    // Process one table at a time
    $chunk_size = 50; // Smaller chunks for batch processing
    $max_execution_time = 30; // 30 seconds per batch
    $start_time = time();
    
    for ( $i = $start_index; $i < count( $tables ); $i++ ) {
        $table = $tables[ $i ];
        $table_name_clean = str_replace( '`', '', $table[0] );
        
        // Check execution time
        if ( ( time() - $start_time ) > $max_execution_time ) {
            return array(
                'completed'   => false,
                'next_table' => $table_name_clean,
                'next_offset' => $offset,
                'progress'   => sprintf( 'Processing table %d of %d', $i + 1, count( $tables ) ),
            );
        }
        
        // Process this table
        $result = $this->process_table_search_replace(
            $table_name_clean,
            $old_url,
            $new_url,
            $offset,
            $chunk_size
        );
        
        if ( isset( $result['error'] ) ) {
            return $result;
        }
        
        // If table not completed, return for next batch
        if ( ! $result['completed'] ) {
            return array(
                'completed'   => false,
                'next_table' => $table_name_clean,
                'next_offset' => $result['next_offset'],
                'progress'   => sprintf( 'Processing table %d of %d', $i + 1, count( $tables ) ),
            );
        }
        
        // Table completed, reset offset for next table
        $offset = 0;
    }
    
    // All tables completed
    return array( 'completed' => true );
}

/**
 * Process one table for search and replace
 *
 * @param string $table_name Table name
 * @param string $old_url Old URL
 * @param string $new_url New URL
 * @param int    $offset Starting offset
 * @param int    $chunk_size Chunk size
 * @return array Status array
 */
private function process_table_search_replace( $table_name, $old_url, $new_url, $offset, $chunk_size ) {
    global $wpdb;
    
    // Get columns
    $columns = $wpdb->get_col( "SHOW COLUMNS FROM `{$table_name}`" );
    if ( empty( $columns ) ) {
        return array( 'completed' => true );
    }
    
    // Get primary key
    $primary_key = null;
    $keys = $wpdb->get_results( "SHOW KEYS FROM `{$table_name}` WHERE Key_name = 'PRIMARY'", ARRAY_A );
    if ( ! empty( $keys ) && isset( $keys[0]['Column_name'] ) ) {
        $primary_key = $keys[0]['Column_name'];
    }
    
    // Build column info cache
    $column_info_cache = array();
    foreach ( $columns as $col ) {
        $col_info = $wpdb->get_row( $wpdb->prepare( "SHOW COLUMNS FROM `{$table_name}` WHERE Field = %s", $col ), ARRAY_A );
        if ( $col_info ) {
            $column_info_cache[ $col ] = $col_info;
        }
    }
    
    // Get chunk of rows
    $rows = $wpdb->get_results(
        $wpdb->prepare(
            "SELECT * FROM `{$table_name}` LIMIT %d OFFSET %d",
            $chunk_size,
            $offset
        ),
        ARRAY_A
    );
    
    if ( empty( $rows ) ) {
        return array( 'completed' => true );
    }
    
    // Process rows
    foreach ( $rows as $row ) {
        // ... (same logic as current implementation)
    }
    
    // Check if more rows exist
    $total_rows = $wpdb->get_var( "SELECT COUNT(*) FROM `{$table_name}`" );
    $next_offset = $offset + $chunk_size;
    
    if ( $next_offset >= $total_rows ) {
        return array( 'completed' => true );
    }
    
    return array(
        'completed'   => false,
        'next_offset' => $next_offset,
    );
}
```

#### B∆∞·ªõc 2: Th√™m API Endpoint cho Batch Processing

```php
// Trong class-api.php
register_rest_route(
    'wpsbm/v1',
    '/finalize_migration_batch',
    array(
        'methods'             => 'POST',
        'callback'            => array( $this, 'handle_finalize_migration_batch' ),
        'permission_callback' => array( $this, 'finalize_migration_permission_check' ),
        'args'                => array(
            'old_url'    => array( /* ... */ ),
            'table_name' => array(
                'required' => false,
                'type'     => 'string',
            ),
            'offset'     => array(
                'required' => false,
                'type'     => 'integer',
                'default'  => 0,
            ),
            'token'      => array( /* ... */ ),
        ),
    )
);
```

#### B∆∞·ªõc 3: Update Frontend JavaScript

```javascript
// Trong admin.js
finalizeAndCleanup: function() {
    // ... existing code ...
    
    // Call batch API instead of single API
    WPSBMAdmin.finalizeMigrationBatch(targetUrl, destinationToken, sourceUrl);
},

finalizeMigrationBatch: function(destinationUrl, destinationToken, sourceUrl) {
    const self = this;
    let tableName = null;
    let offset = 0;
    
    const processBatch = function() {
        const apiUrl = destinationUrl.replace(/\/$/, '') + '/wp-json/wpsbm/v1/finalize_migration_batch';
        
        $.ajax({
            url: apiUrl,
            type: 'POST',
            data: {
                old_url: sourceUrl,
                token: destinationToken,
                table_name: tableName,
                offset: offset
            },
            success: function(response) {
                if (response.completed) {
                    // All done, proceed to cleanup
                    WPSBMAdmin.cleanupRemote(destinationUrl, destinationToken, function() {
                        WPSBMAdmin.cleanupLocal(function() {
                            WPSBMAdmin.showMigrationSuccess(destinationUrl);
                        });
                    });
                } else {
                    // Continue with next batch
                    tableName = response.next_table;
                    offset = response.next_offset || 0;
                    
                    // Update progress
                    if (response.progress) {
                        console.log(response.progress);
                    }
                    
                    // Call next batch after short delay
                    setTimeout(processBatch, 100);
                }
            },
            error: function(xhr) {
                // Handle error
                WPSBMAdmin.showStatusMessage(
                    'Finalization failed: ' + (xhr.responseJSON?.message || 'Unknown error'),
                    'error',
                    $('#wpsbm-migration-status')
                );
            }
        });
    };
    
    // Start first batch
    processBatch();
}
```

---

## üìä So S√°nh Hi·ªáu NƒÉng

### SQL Import

| Ph∆∞∆°ng Ph√°p | RAM Usage (100MB file) | Th·ªùi Gian | R·ªßi Ro |
|------------|----------------------|-----------|--------|
| **Hi·ªán t·∫°i** | 300-400MB | 30-60s | ‚ùå High (memory kill) |
| **Streaming** | 10-20MB | 60-90s | ‚úÖ Low |

### Search & Replace

| Ph∆∞∆°ng Ph√°p | Timeout Risk | Database Size Limit | User Experience |
|------------|-------------|---------------------|-----------------|
| **Hi·ªán t·∫°i** | ‚ùå High (>100MB) | ~50MB | ‚ö†Ô∏è Ch·ªù l√¢u, c√≥ th·ªÉ fail |
| **Batch** | ‚úÖ Low | Unlimited | ‚úÖ Progress tracking, reliable |

---

## üöÄ K·∫ø Ho·∫°ch Tri·ªÉn Khai

### Phase 1: Quick Win (1-2 gi·ªù)
1. ‚úÖ Th√™m file size check tr∆∞·ªõc khi import
2. ‚úÖ Th√™m memory limit check
3. ‚úÖ Th√™m warning message cho file l·ªõn

### Phase 2: Streaming Parser (4-6 gi·ªù)
1. Implement `split_sql_queries_streaming()`
2. Test v·ªõi file SQL l·ªõn
3. Fallback v·ªÅ method c≈© n·∫øu streaming fail

### Phase 3: Batch Processing (8-12 gi·ªù)
1. Implement batch API endpoint
2. Update frontend JavaScript
3. Add progress tracking UI
4. Test v·ªõi database l·ªõn

---

## ‚ö†Ô∏è L∆∞u √ù

1. **Backward Compatibility**: Gi·ªØ method c≈© l√†m fallback
2. **Testing**: Test k·ªπ v·ªõi database th·∫≠t tr∆∞·ªõc khi deploy
3. **Monitoring**: Th√™m logging ƒë·ªÉ track performance
4. **Documentation**: Update README v·ªõi limitations v√† recommendations

---

**T√°c gi·∫£**: Code Improvement Proposal
**Ng√†y**: $(date)
**Version**: 1.1.0 (Proposed)

